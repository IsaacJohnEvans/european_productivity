{"cells":[{"cell_type":"code","execution_count":173,"metadata":{},"outputs":[],"source":["#coding utf8\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","import tensorflow as tf\n","import keras_tuner as kt\n","from tensorflow import keras\n","from tensorflow.keras import layers, metrics\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn import svm\n"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[],"source":["'''\n","Deprecated load data function\n","'''\n","def load_data():\n","    args = []\n","    prod_df = pd.read_csv('data\\productivity.csv')\n","    prod_new_df = pd.read_csv('data\\productivity_new.csv')\n","    sentiment_df = pd.read_csv('data\\sentiment.csv')\n","    hours_worked_df = pd.read_csv('data\\lfsa_ewhun2_1_Data.csv')\n","    productivity_df = pd.read_csv('./data/GDP_per_quarter.csv') \n","    unem_df = pd.read_csv('./data/unem.csv')\n","    covid_df = pd.read_csv('./data/DataPerWeek.csv')\n","    unem_df.fillna(0)\n","    productivity_df.fillna(0)\n","    sentiment_df.fillna(0)\n","    prod_df.fillna(0)\n","    covid_df.fillna(0)\n","    args += [prod_df, sentiment_df, hours_worked_df, prod_new_df, productivity_df, unem_df, covid_df]\n","    return args\n"]},{"cell_type":"code","execution_count":268,"metadata":{},"outputs":[],"source":["'''\n","Functions for loading in and combining data\n","'''\n","def load_df(file_name, sheet = 'Sheet 1'):\n","    '''\n","    Load a file into a data frame that is quarterly from the Eurostat website\n","    '''\n","    df = pd.read_excel(file_name, sheet_name=sheet)\n","    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n","    df.replace(':', np.nan, inplace=True)\n","    df.index = df.iloc[:, 0]\n","    df.drop(df.columns[[0]], axis=1, inplace=True)\n","    for i in df.columns[:]:\n","        df[i] = df[i].apply(pd.to_numeric, errors=\"coerce\")\n","    df.interpolate(method='linear', inplace=True, axis = 1)\n","    df.sort_index(inplace=True)\n","    df = df.rename({'Germany (until 1990 former territory of the FRG)': 'Germany'})\n","    return df\n","\n","def create_per_employeer(GDP_df, HW_df, employees_df):\n","    ''' \n","    Inputs: GDP, hours worked, and employees dataframes\n","    Output: dataframe with per-employee GDP and per hour worked GDP\n","    '''\n","    cols =(list(set(GDP_df.columns) and set(employees_df.columns) and set(HW_df.columns)))\n","    cols.sort()\n","    idx = cols.pop()\n","    per_employee_df = pd.DataFrame(index=GDP_df.index, columns=cols)\n","    per_HW_df = pd.DataFrame(index=GDP_df.index, columns=cols)\n","    for i in cols:\n","        per_employee_df[i] = GDP_df[i]/employees_df[i]\n","        per_HW_df[i] = per_employee_df[i]/HW_df[i]\n","    return per_employee_df, per_HW_df\n","\n","def country_code_to_name(df):\n","    '''\n","    Renames country codes to country names\n","    '''\n","    df = df.rename({'AUT': 'Austria', 'BEL': 'Belgium', 'DEU': 'Germany','EST': 'Estonia','FIN': 'Finland','ESP': 'Spain','FRA': 'France','GRC': 'Greece','IRL': 'Ireland','ITA': 'Italy','LTU': 'Lithuania','LUX': 'Luxembourg','LVA': 'Latvia','PRT': 'Portugal','NLD': 'Netherlands','SVK': 'Slovakia','SVN': 'Slovenia','ISL': 'Iceland','GBR': 'United Kingdom','CHE': 'Switzerland','CZE': 'Cezch Republic','DNK': 'Denmark','HUN': 'Hungary','NOR': 'Norway','POL': 'Poland','SWE': 'Sweden'})\n","    return df\n","\n","def yearly_to_quarterly(df):\n","    '''\n","    Inputs: df\n","    Converts the data from yearly to quarterly\n","    Outputs: quarterly_df\n","    '''\n","    data = df.to_numpy(dtype=np.float64)\n","    data = np.repeat(data, 4, axis = 1)\n","    quarterly_df = pd.DataFrame(data)\n","    quarterly_df.index = df.index\n","    quarterly_df.columns = GDP_df.columns[(int(df.columns[0]) - 1975)*4:(int(df.columns[-1]) - 2021)*4]\n","    return quarterly_df\n","\n","def match_df(dfs):\n","    ''' \n","    Input : dataframes\n","    This function matches dataframes by their index and column \n","    Output: matched dataframes\n","    '''\n","    idx = set(dfs[0].index)\n","    cols = set(dfs[0].columns)\n","    for i in dfs:\n","        idx = idx.intersection(set(i.index))\n","        cols = cols.intersection(set(i.columns))\n","    cols = list(cols)\n","    idx = list(idx)\n","    cols.sort()\n","    idx.sort()\n","    for i in range(len(dfs)):\n","        dfs[i] = dfs[i].loc[idx]\n","        dfs[i] = dfs[i][cols]\n","    return dfs\n","\n"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[],"source":["'''\n","Functions for time series prediction\n","'''\n","def process_data(X, y, split_point, time_step, data_memory):\n","    '''\n","    Inputs: X, y, split_point, time_step, data_memory\n","    Splits data into training and testing data\n","    Outputs: X_train, X_test, y_train, y_test\n","    '''\n","    X_norm, X_attrs, y_norm, y_attrs = normalise(X, y)\n","    split_point = int(X_norm.shape[0] *split_point)\n","    y_norm = np.roll(y_norm, -time_step)\n","    nrows = X_norm.shape[0]\n","    samples = X_norm.shape[1]\n","    X_norm = np.repeat(X_norm, data_memory, 0).reshape(nrows, data_memory, samples)\n","    x_train, x_test, y_train, y_test = train_test_split(X_norm, y_norm, split_point)\n","    return x_train, x_test, y_train, y_test, nrows, samples, X_norm, y_norm, X_attrs, y_attrs\n","\n","def normalise(X, y):\n","    '''\n","    Inputs: X, y\n","    Normalises the data by subtracting the mean and dividing by the standard deviation\n","    Outputs : X_norm, y_norm, X_attrs, y_attrs\n","    '''\n","    X_attrs = np.zeros((X.shape[-1], 2))\n","    y_attrs = np.zeros((y.shape[-1], 2))\n","    for i in range(X.shape[-1]):\n","        X_attrs[i, :] = [np.mean(X[:, i]), np.var(X[:, i])]\n","        X[:, i] = (X[:, i] - np.mean(X[:, i]))/np.var(X[:, i])**0.5\n","    for i in range(y.shape[-1]):\n","        y_attrs[i, :] = [np.mean(y[:, i]), np.var(y[:, i])]\n","        y[:, i] = (y[:, i] - np.mean(y[:, i]))/np.var(y[:, i])**0.5  \n","    return X, X_attrs, y, y_attrs\n","\n","def train_test_split(X, y, split_point):\n","    '''\n","    Splits the data into training and testing data\n","    '''\n","    x_train = X[:split_point, :, :]\n","    x_test = X[split_point:, :, :]\n","    y_train = y[:split_point]\n","    y_test = y[split_point:]\n","    return x_train, x_test, y_train, y_test\n","        \n","def create_model(layers, input_shape, print_summary):\n","    '''\n","    Creates a model with the specified layers\n","    '''\n","    model = keras.Sequential(layers)\n","    model.build(input_shape=input_shape)\n","    model.compile(loss='mse', optimizer='adam', metrics = [tf.keras.metrics.MeanSquaredError()])\n","    if print_summary:\n","        model.summary()\n","    return model\n","\n","def run_model(X, y, time_step, data_memory, epochs, batch_size, model_layer, split_point):\n","    '''\n","    Inputs: X, y, time_step, data_memory, epochs, batch_size, model_layer, split_point\n","    Runs the model on the data\n","    Outputs: model, history\n","    '''\n","    x_train, x_test, y_train, y_test, nrows, samples, X_norm, y_norm, X_attrs, y_attrs = process_data(X, y, split_point, time_step, data_memory)\n","    input_shape = (x_train.shape[0], data_memory, samples)\n","    model = create_model(model_layer, input_shape, print_summary)\n","    history = model.fit(x_train, y_train, validation_split = 0.1, epochs= epochs , batch_size=batch_size)\n","    y_pred_norm = np.concatenate((model.predict(x_train[:, :, :]), model.predict(x_test[:, :, :])))\n","    y_pred_norm = np.roll(y_pred_norm, 1, axis = 1)\n","    y_pred = np.roll(y_pred_norm *y_attrs[:, 1]**0.5 + y_attrs[:, 0] , 0)\n","    mse = metrics.MeanSquaredError()\n","    mse.update_state(y_norm, y_pred_norm)\n","    test_loss = mse.result().numpy()\n","    print(test_loss)\n","    train_loss = history.history['loss'][-1]\n","    val_loss = history.history['val_loss'][-1]\n","    model_performance = [time_step, data_memory, samples, epochs, batch_size, train_loss, val_loss, test_loss]\n","    df_model = pd.DataFrame(model_performance).transpose()\n","    df_model.to_csv('model_performance.csv', mode = 'a', header= False)\n","    return y, y_pred, history\n"]},{"cell_type":"code","execution_count":270,"metadata":{},"outputs":[],"source":["'''\n","Loads in gross domestic product, hours worked and employees data\n","Returns GDP per employee and GDP per hour worked\n","'''\n","GDP_df =  load_df('./data/GDP_per_quarter_2.xlsx') * 1e6\n","HW_df = load_df('./data/hours_worked.xlsx')\n","employees_df = load_df('./data/Employees.xlsx') * 1e3\n","per_employee_df, per_HW_df = create_per_employeer(GDP_df, HW_df, employees_df)\n","\n","#per_HW_df.iloc[4, :].T.plot(legend = False)"]},{"cell_type":"code","execution_count":271,"metadata":{},"outputs":[],"source":["'''\n","Depression data\n","'''\n","dep_df = pd.read_csv('data/depression_by_age.csv') \n","dep_df = dep_df.drop(['Prevalence - Depressive disorders - Sex: Both - Age: 10 to 14 (Percent)','Prevalence - Depressive disorders - Sex: Both - Age: All Ages (Percent)','Prevalence - Depressive disorders - Sex: Both - Age: 70+ years (Percent)','Prevalence - Depressive disorders - Sex: Both - Age: Age-standardized (Percent)', 'Prevalence - Depressive disorders - Sex: Both - Age: 15-49 years (Percent)'],axis=1)\n","a = ['Belgium','Bulgaria','Denmark','Germany','Estonia','Ireland','Greece','Spain','France','Croatia','Italy','Cyprus','Latvia','Lithuania','Luxemburg','Hungary','Malta','Netherlands','Austria','Poland','Portugal','Romania','Slovenia','Slovakia','Finland','Sweden','Iceland','Norway','Switzerland','United Kingdom','Montenegro','North Macedonia','Serbia','Turkey']\n","dep_df = dep_df[dep_df['Entity'].isin(a)]\n","dep_df['Age:15-69_depression_average']=dep_df.iloc[:,3:7].mean(axis=1,skipna=True)\n","dep_df = dep_df.pivot_table('Age:15-69_depression_average', ['Entity', 'Code'], 'Year')\n","dep_df = dep_df.reset_index('Code')\n","del dep_df['Code']\n","dep_quarterly_df = yearly_to_quarterly(dep_df)\n","\n","'''\n","Education data\n","'''\n","education_dfs = [None] * 4\n","for i in range(4):\n","    education_dfs[i] = load_df('./data/Education.xlsx', 'Sheet ' + str(4*i + 1))\n","    education_dfs[i] = yearly_to_quarterly(education_dfs[i])\n","    education_dfs[i] = education_dfs[i].rename({'Germany (until 1990 former territory of the FRG)': 'Germany'})\n","\n","'''\n","Inflation data\n","'''\n","inf_df = pd.read_csv('data/Quarterly_infilation.csv')\n","inf_df =inf_df.drop(['SUBJECT', 'MEASURE','FREQUENCY','Flag Codes'], axis=1)\n","inf_df = inf_df.pivot_table('Value', ['LOCATION', 'INDICATOR'], 'TIME')\n","inf_df = country_code_to_name(inf_df)\n","inf_df = inf_df.reset_index('INDICATOR')\n","del inf_df['INDICATOR']\n","inf_df = inf_df.rename({'Germany (until 1990 former territory of the FRG)': 'Germany'})\n","\n","'''\n","Unemployment data\n","'''\n","unem_df = pd.read_csv('./data/unem.csv')\n","unem_df.fillna(0)\n","unem_df = unem_df[['LOCATION', 'TIME', 'Value']]\n","unem_df = unem_df.pivot_table('Value',  ['LOCATION'],'TIME')\n","unem_df = country_code_to_name(unem_df)"]},{"cell_type":"code","execution_count":275,"metadata":{},"outputs":[{"data":{"text/plain":["(35, 52)"]},"execution_count":275,"metadata":{},"output_type":"execute_result"}],"source":["dfs = [per_employee_df, per_HW_df] + education_dfs\n","matched_dfs = match_df(dfs)\n","data = np.zeros((len(matched_dfs[0].index), len(matched_dfs[0].columns),  len(matched_dfs)))\n","for i in range(len(matched_dfs)):\n","    data[:, :, i] = matched_dfs[i].to_numpy(dtype=np.float64)\n","data.shape\n","matched_dfs[0].shape"]},{"cell_type":"code","execution_count":273,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(38, 55) (55, 1)\n"]}],"source":["X = per_HW_df.to_numpy()[:, :]\n","y = np.array([per_HW_df.to_numpy()[0, :]]).T\n","print(X.shape, y.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (34, 5, 8)                448       \n","                                                                 \n"," lstm (LSTM)                 (34, 4)                   208       \n","                                                                 \n"," dense_1 (Dense)             (34, 8)                   40        \n","                                                                 \n"," dense_2 (Dense)             (34, 1)                   9         \n","                                                                 \n","=================================================================\n","Total params: 705\n","Trainable params: 705\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","30/30 [==============================] - 3s 15ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 2/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 3/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 4/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 5/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 6/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 7/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 8/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 9/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n","Epoch 10/10\n","30/30 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n"]},{"ename":"InvalidArgumentError","evalue":"Incompatible shapes: [38,1] vs. [55,1] [Op:SquaredDifference]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[1;32mC:\\Users\\ISAACE~1\\AppData\\Local\\Temp/ipykernel_24288/106302715.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 layers.Dense(1)]\n\u001b[0;32m      8\u001b[0m \u001b[0mprint_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_memory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Users\\ISAACE~1\\AppData\\Local\\Temp/ipykernel_24288/263216777.py\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(X, y, time_step, data_memory, epochs, batch_size, model_layer, split_point)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_norm\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0my_attrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_attrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mmse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Apps\\lib\\site-packages\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Apps\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Apps\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Apps\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Apps\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Apps\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m     return super(MeanMetricWrapper, self).update_state(\n\u001b[0;32m    731\u001b[0m         matches, sample_weight=sample_weight)\n","\u001b[1;32mC:\\Apps\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Apps\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1327\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m   \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [38,1] vs. [55,1] [Op:SquaredDifference]"]}],"source":["time_step, data_memory, epochs, batch_size, split_point = 5, 5, 10, 1, 0.9\n","\n","load_model_bool, load_model, save_model, save_fig = False, 'EU_model', 'EU_model', 'EU'\n","model_layer = [layers.Dense(8, activation= 'linear'),\n","                layers.LSTM(4,activation= 'sigmoid', dropout = 0.1, recurrent_dropout = 0.1, return_sequences=False),\n","                layers.Dense(8, activation='linear'),\n","                layers.Dense(1)]\n","print_summary = True\n","y, y_pred, history = run_model(X, y, time_step, data_memory, epochs, batch_size, model_layer, split_point)\n","\n"]}],"metadata":{"interpreter":{"hash":"4cabb15ab25fea23f8059180816881b2dbbe348c8bd98378d45c058900a30581"},"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
